### ðŸš§ Work-in-progress Features

- [ ] **Additional quantization formats**
  - [ ] Q8 
  - [ ] Q4
  - [ ] INT8 native support for GPUs
- [ ] **Additional architectures and model format**
  - [ ] Mistral/Mixtral models
  - [ ] Qwen
  - [ ] Gemma/Gemma2 models
  - [ ] TinyLlamas
  - [ ] SafeTensors format
  - [ ] PyTorch checkpoint loading
  - [ ] Automatic model conversion utilities
- [ ] **Advanced inference capabilities**
  - [ ] Batch inference support
  - [ ] Speculative decoding
- [ ] **Performance optimizations**
  - [ ] Multi-GPU support
  - [X] Memory-efficient attention mechanisms
  - [ ] More Kernel fusion improvements
- [ ] **LangChain4j integration**
- [ ] **GraalVM Native Image**
